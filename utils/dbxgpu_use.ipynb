{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linux based systems on nvidia gpus (Databricks)\n",
    "#### https://github.com/Unstructured-IO/issues/2506"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%apt-get update \n",
    "%apt-get install --yes poppler-utils tesseract-ocr libmagic-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sh watch -n0.1 nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Databricks Documentation for DBR System libraries \n",
    "https://docs.databricks.com/aws/en/release-notes/runtime/15.4lts-ml\n",
    "\n",
    "For GPU clusters, Databricks Runtime ML includes the following NVIDIA GPU libraries:\n",
    "CUDA 12.1\n",
    "cusolver 11.4.5.107-1\n",
    "cupti 12.1\n",
    "cuDNN 8.9.0.131-1\n",
    "NCCL 2.17.1\n",
    "TensorRT 8.6.1.6-1\n",
    "\n",
    "### ONNX compatibility with TensorRT \n",
    "https://onnxruntime.ai/docs/execution-providers/TensorRT-ExecutionProvider.html#requirements\n",
    "\n",
    "ONNX Runtime\tTensorRT\tCUDA\n",
    "main\t10.9\t12.0-12.8, 11.8\n",
    "1.21\t10.8\t12.0-12.8, 11.8\n",
    "1.20\t10.4\t12.0-12.6, 11.8\n",
    "1.19\t10.2\t12.0-12.6, 11.8\n",
    "1.18\t10.0\t11.8,      12.0-12.6\n",
    "1.17\t8.6\t    11.8,      12.0-12.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.21.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check version of ONNX runtime\n",
    "import onnxruntime \n",
    "onnxruntime.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check available EPs\n",
    "import onnxruntime \n",
    "from loguru import logger \n",
    "available_providers = onnxruntime.get_all_providers() \n",
    "\n",
    "ordered_providers = [\n",
    "    \"TensorrtExecutionProvider\",\n",
    "    \"CUDAExecutionProvider\",\n",
    "    \"CPUExecutionProvider\"\n",
    "]\n",
    "\n",
    "providers = [provider for provider in ordered_providers if provider in available_providers]\n",
    "\n",
    "logger.info(f\"Available ONNX runtime providers: {providers}\")\n",
    "\n",
    "if \"CUDAExecutionProvider\" not in providers:\n",
    "    logger.info(\"If you expected to see CUDAExecutionProvider and if is not there, \"\n",
    "                \"you may need to install the appropriate version of onnxruntime-gpu\"\n",
    "                \"for your CUDA toolkit\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use GPU with unstructured.io / Installing Tensorrt and CUDA EPs\n",
    "%pip install -Uq onnxruntime-gpu==1.21.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%sh` not found (But cell magic `%%sh` exists, did you mean that instead?).\n"
     ]
    }
   ],
   "source": [
    "# Get version of TensorRT\n",
    "#%sh dpkg -l | grep nvinfer\n",
    "#%sh dpkg -l | grep TensorRT\n",
    "# Get path of TensorRT\n",
    "#%sh find / -name 'libnvinfer.so*' 2>/dev/null\n",
    "# Add tensorRT path to LD_LIBRARY_PATH \n",
    "# %sh export LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
